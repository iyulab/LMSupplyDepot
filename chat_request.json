{
    "model": "llama-3-1b",
    "messages": [
        {
            "role": "system",
            "content": "You are a helpful assistant."
        },
        {
            "role": "user",
            "content": "Hello! Can you tell me a short joke?"
        }
    ],
    "max_tokens": 100,
    "temperature": 0.7
}